{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir, remove\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "import spacetrack.operators as op\n",
    "from spacetrack import SpaceTrackClient\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "spacetrack_usr, spacetrack_pwd = open('./spacetrack_pwd.key').read()[:-1].split(',')\n",
    "st = SpaceTrackClient(identity=spacetrack_usr, password=spacetrack_pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_socrates_data(path):\n",
    "    '''\n",
    "    Builds a dataframe out of all the socrates data files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Relative file path of socrates files\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : Pandas Dataframe\n",
    "        Combined set of all socrates data\n",
    "    '''\n",
    "    files = [ (match[0],match[1]) for f in listdir(path) if isfile(join(path, f))  if (match:=re.search('^socrates_([0-9]{14})\\.csv(\\.gz)?$', f))]\n",
    "    files\n",
    "\n",
    "    # Build single dataset\n",
    "    df = pd.DataFrame()\n",
    "    for file,date in files:\n",
    "        tmp_df = pd.read_csv(path + file)\n",
    "        df = pd.concat([df,tmp_df])\n",
    "\n",
    "\n",
    "    # Fix dates and timedeltas\n",
    "    df['extract_date'] = pd.to_datetime(df['extract_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    df['start_time'] = pd.to_datetime(df['start_time'], format='%Y %b %d %H:%M:%S.%f')\n",
    "    df['tca_time'] = pd.to_datetime(df['tca_time'], format='%Y %b %d %H:%M:%S.%f')\n",
    "    df['stop_time'] = pd.to_datetime(df['stop_time'], format='%Y %b %d %H:%M:%S.%f')\n",
    "    df['sat1_days_epoch'] = pd.to_timedelta(df['sat1_days_epoch'], 'd')\n",
    "    df['sat2_days_epoch'] = pd.to_timedelta(df['sat2_days_epoch'], 'd')\n",
    "    df['sat1_last_epoch'] = df['tca_time'] - df['sat1_days_epoch']\n",
    "    df['sat2_last_epoch'] = df['tca_time'] - df['sat2_days_epoch']\n",
    "\n",
    "    # Add \"pair\" column\n",
    "    df['sat_pair'] = df.apply(lambda x: x['sat1_name'] + '-' + x['sat2_name'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "group_num = 0\n",
    "def set_group_number(x):\n",
    "    '''\n",
    "    Returns group number for each row (via pd.apply)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : Boolean\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    group_num : int\n",
    "    '''\n",
    "    global group_num\n",
    "    if x:\n",
    "        group_num += 1\n",
    "    return group_num\n",
    "\n",
    "def get_socrates_cleaned_data(path):\n",
    "    '''\n",
    "    Builds a dataframe out of all the socrates data files\n",
    "    and remove duplicates and sorts\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        Relative file path of socrates files\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : Pandas Dataframe\n",
    "        Combined set of all socrates data\n",
    "    '''\n",
    "    df = get_all_socrates_data(path)\n",
    "\n",
    "    # Clean the data\n",
    "    # Remove duplicates - keep the first occurence of a sat-pair and tca_time\n",
    "    df = df.drop_duplicates(subset=['sat_pair', 'tca_time'], keep='first')\n",
    "\n",
    "    # Set a group number (some entries have TCA times that change slightly and these will be grouped together)\n",
    "    df = df.sort_values(['sat_pair','tca_time'])\n",
    "    df['group'] = ((df['sat_pair'] != df['sat_pair'].shift(1)) | (df['tca_time']-df['tca_time'].shift(1) > pd.Timedelta('1 min'))).apply(set_group_number)\n",
    "\n",
    "    # Resort\n",
    "    df = df.sort_values(['group','extract_date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_socrates_with_tle_data(df, tle_data_path):\n",
    "    '''\n",
    "    Merges the socrates data with the TLE data to create a new dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : Pandas Dataframe\n",
    "        The socrates dataframe\n",
    "        \n",
    "    tle_data_path : str\n",
    "        Relative file path of TLE data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : Pandas Dataframe\n",
    "        Trimmed set of socrates data with TLE data (from file)\n",
    "    '''\n",
    "    # Get last row (most recent socrates record) of each group\n",
    "    g = df.groupby('group')\n",
    "    gdf = g.tail(1)\n",
    "\n",
    "    # Open the TLE Pickle file and merge\n",
    "    tle_df = pd.read_pickle(tle_data_path)\n",
    "    gdf = gdf.merge(tle_df, left_on=['sat_pair','tca_time', 'sat1_norad', 'sat2_norad'], right_on=['sat_pair','tca_time', 'sat1_norad', 'sat2_norad'], how='left')\n",
    "    \n",
    "    return gdf\n",
    "    \n",
    "def get_all_socrates_and_tle_data(socrates_files_path, tle_file_path):\n",
    "    '''\n",
    "    Returns Socrates and TLE data joined together\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    socrates_files_path : str\n",
    "        Relative path to socrates data\n",
    "        \n",
    "    tle_file_path : str\n",
    "        Relative file path of TLE data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    soc_df : Pandas Dataframe\n",
    "        Socrates complete data\n",
    "        \n",
    "    tle_df : Pandas Dataframe\n",
    "        Trimmed set of socrates data with TLE data (from file only)\n",
    "    '''\n",
    "    tle_file_path = '../../data/socrates_tca_gp_history_tle.pkl.gz'\n",
    "    \n",
    "    soc_df = get_socrates_cleaned_data(socrates_files_path)\n",
    "    tle_df = get_socrates_with_tle_data(soc_df, tle_file_path)\n",
    "    \n",
    "    # This enables progress_apply so we get a progressbar\n",
    "    #tqdm.pandas(desc=\"Getting TLE Data from API...\")\n",
    "    \n",
    "    # Get missing TLE data from API\n",
    "    #gdf['sat1_tle'],gdf['sat1_tle_epoch'],gdf['sat2_tle'],gdf['sat2_tle_epoch'] =zip(*gdf.progress_apply(get_missing_tle_gp_history, axis=1))\n",
    "    #gdf[['sat_pair','tca_time','sat1_norad','sat2_norad','sat1_tle','sat1_tle_epoch','sat2_tle','sat2_tle_epoch']].to_pickle(tle_file_path, 'gzip')\n",
    "    \n",
    "    return soc_df, tle_df\n",
    "\n",
    "socrates_files_path = '../../data/socrates/'\n",
    "tle_file_path = '../../data/socrates_tca_gp_history_tle.pkl.gz'\n",
    "\n",
    "soc_df, tle_df = get_all_socrates_and_tle_data(socrates_files_path, tle_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "tmp_tle_file = './tle2.csv'\n",
    "\n",
    "# Create a new df of the socrates entries with missing TLE data\n",
    "mtle_df1 = tle_df[tle_df['sat1_tle'].isnull()][['sat1_norad','sat1_last_epoch']].rename(columns={'sat1_norad':'norad','sat1_last_epoch':'last_epoch'})\n",
    "mtle_df2 = tle_df[tle_df['sat2_tle'].isnull()][['sat2_norad','sat2_last_epoch']].rename(columns={'sat2_norad':'norad','sat2_last_epoch':'last_epoch'})\n",
    "miss_tle_df = pd.concat([mtle_df1, mtle_df2])\n",
    "miss_tle_df = miss_tle_df.sort_values('last_epoch')\n",
    "\n",
    "# Split the missing TLE dataset into bins\n",
    "bin_size = 100\n",
    "num_bins = round(len(miss_tle_df) / bin_size + 0.49999)\n",
    "miss_tle_df['bin'] = pd.qcut(miss_tle_df['last_epoch'], num_bins, labels=list(range(num_bins)))\n",
    "print (num_bins)\n",
    "# len(miss_tle_df[miss_tle_df['bin'] < 201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████▏                                   | 27/48 [01:29<00:40,  1.93s/it]C:\\Users\\mille\\Anaconda3\\envs\\siads-orbital\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418: UserWarning: Discarding nonzero nanoseconds in conversion\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [03:09<00:00,  3.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each bin - make a request to SpaceTrack for all norads within that bin with a min/max daterange\n",
    "# This will save the data to a CSV file we will parse next (we save to ensure an interrupted progress\n",
    "# does not result in a massive amount of lost data)\n",
    "count = 0\n",
    "for b in tqdm(range(num_bins)):\n",
    "#     if b > 0:\n",
    "    tmp_df = miss_tle_df[miss_tle_df['bin'] == b]\n",
    "    min_epoch = tmp_df['last_epoch'].min().to_pydatetime()\n",
    "    max_epoch = tmp_df['last_epoch'].max().to_pydatetime()\n",
    "    epoch_range = op.inclusive_range(min_epoch - timedelta(minutes=5), max_epoch + timedelta(minutes=5))\n",
    "    all_norads = list(tmp_df['norad'].unique())\n",
    "    all_data = st.gp_history(norad_cat_id = all_norads, epoch=epoch_range)\n",
    "\n",
    "    # Write the data to a file\n",
    "    for idx, row in tmp_df.iterrows():\n",
    "        d = list(filter(lambda rec: (rec['NORAD_CAT_ID']==str(row['norad'])) & (abs(pd.to_datetime(rec['EPOCH'], format='%Y-%m-%dT%H:%M:%S.%f') - row['last_epoch']) < pd.Timedelta('5 min')), all_data))[0]\n",
    "        with open(tmp_tle_file, 'a') as f:\n",
    "                s = ','.join([str(row['norad']), row['last_epoch'].strftime('%Y%m%d%H%M%S%f'), d['TLE_LINE1'], d['TLE_LINE2'], d['EPOCH']]) \n",
    "                f.write(s + '\\n')\n",
    "#         count += 1\n",
    "#         if count >200:\n",
    "#             print(f'Finished upto bin {b-1}')\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norad</th>\n",
       "      <th>last_epoch</th>\n",
       "      <th>tle_line1</th>\n",
       "      <th>tle_line2</th>\n",
       "      <th>tle_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46956</td>\n",
       "      <td>2020-12-07 10:26:42.503000</td>\n",
       "      <td>1 46956U 20085AD  20342.43569727 +.00009211 +0...</td>\n",
       "      <td>2 46956 097.3684 116.6896 0014474 252.4864 107...</td>\n",
       "      <td>2020-12-07T10:27:24.244128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46956</td>\n",
       "      <td>2020-12-07 10:26:46.397000</td>\n",
       "      <td>1 46956U 20085AD  20342.43569727 +.00009211 +0...</td>\n",
       "      <td>2 46956 097.3684 116.6896 0014474 252.4864 107...</td>\n",
       "      <td>2020-12-07T10:27:24.244128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46956</td>\n",
       "      <td>2020-12-07 10:26:58.711000</td>\n",
       "      <td>1 46956U 20085AD  20342.43569727 +.00009211 +0...</td>\n",
       "      <td>2 46956 097.3684 116.6896 0014474 252.4864 107...</td>\n",
       "      <td>2020-12-07T10:27:24.244128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46956</td>\n",
       "      <td>2020-12-07 10:27:03.471000</td>\n",
       "      <td>1 46956U 20085AD  20342.43569727 +.00009211 +0...</td>\n",
       "      <td>2 46956 097.3684 116.6896 0014474 252.4864 107...</td>\n",
       "      <td>2020-12-07T10:27:24.244128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46956</td>\n",
       "      <td>2020-12-07 10:27:19.784000</td>\n",
       "      <td>1 46956U 20085AD  20342.43569727 +.00009211 +0...</td>\n",
       "      <td>2 46956 097.3684 116.6896 0014474 252.4864 107...</td>\n",
       "      <td>2020-12-07T10:27:24.244128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8742</th>\n",
       "      <td>46687</td>\n",
       "      <td>2020-12-21 06:00:40.339999</td>\n",
       "      <td>1 46687U 20073T   20356.25001157 -.00032326  0...</td>\n",
       "      <td>2 46687  53.0537 156.4222 0002423  24.7100 179...</td>\n",
       "      <td>2020-12-21T06:00:00.999648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8743</th>\n",
       "      <td>46698</td>\n",
       "      <td>2020-12-21 06:00:40.531000</td>\n",
       "      <td>1 46698U 20073AE  20356.25001157  .00039952  0...</td>\n",
       "      <td>2 46698  53.0541 156.4452 0002064  21.4820 170...</td>\n",
       "      <td>2020-12-21T06:00:00.999648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8744</th>\n",
       "      <td>46694</td>\n",
       "      <td>2020-12-21 06:00:41.914000</td>\n",
       "      <td>1 46694U 20073AA  20356.25001157 -.00011172  0...</td>\n",
       "      <td>2 46694  53.0543 156.4335 0002340  36.3499 163...</td>\n",
       "      <td>2020-12-21T06:00:00.999648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745</th>\n",
       "      <td>43171</td>\n",
       "      <td>2020-12-21 06:07:21.751000</td>\n",
       "      <td>1 43171U 18011C   20356.25496003  .00000239  0...</td>\n",
       "      <td>2 43171  35.0001 328.2871 0003494 312.5159  47...</td>\n",
       "      <td>2020-12-21T06:07:08.546592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8746</th>\n",
       "      <td>41456</td>\n",
       "      <td>2020-12-21 06:20:43.381000</td>\n",
       "      <td>1 41456U 16025A   20356.26421947  .00000032  0...</td>\n",
       "      <td>2 41456  98.1814   0.4081 0001288  80.5642 279...</td>\n",
       "      <td>2020-12-21T06:20:28.562208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8747 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      norad                 last_epoch  \\\n",
       "0     46956 2020-12-07 10:26:42.503000   \n",
       "1     46956 2020-12-07 10:26:46.397000   \n",
       "2     46956 2020-12-07 10:26:58.711000   \n",
       "3     46956 2020-12-07 10:27:03.471000   \n",
       "4     46956 2020-12-07 10:27:19.784000   \n",
       "...     ...                        ...   \n",
       "8742  46687 2020-12-21 06:00:40.339999   \n",
       "8743  46698 2020-12-21 06:00:40.531000   \n",
       "8744  46694 2020-12-21 06:00:41.914000   \n",
       "8745  43171 2020-12-21 06:07:21.751000   \n",
       "8746  41456 2020-12-21 06:20:43.381000   \n",
       "\n",
       "                                              tle_line1  \\\n",
       "0     1 46956U 20085AD  20342.43569727 +.00009211 +0...   \n",
       "1     1 46956U 20085AD  20342.43569727 +.00009211 +0...   \n",
       "2     1 46956U 20085AD  20342.43569727 +.00009211 +0...   \n",
       "3     1 46956U 20085AD  20342.43569727 +.00009211 +0...   \n",
       "4     1 46956U 20085AD  20342.43569727 +.00009211 +0...   \n",
       "...                                                 ...   \n",
       "8742  1 46687U 20073T   20356.25001157 -.00032326  0...   \n",
       "8743  1 46698U 20073AE  20356.25001157  .00039952  0...   \n",
       "8744  1 46694U 20073AA  20356.25001157 -.00011172  0...   \n",
       "8745  1 43171U 18011C   20356.25496003  .00000239  0...   \n",
       "8746  1 41456U 16025A   20356.26421947  .00000032  0...   \n",
       "\n",
       "                                              tle_line2  \\\n",
       "0     2 46956 097.3684 116.6896 0014474 252.4864 107...   \n",
       "1     2 46956 097.3684 116.6896 0014474 252.4864 107...   \n",
       "2     2 46956 097.3684 116.6896 0014474 252.4864 107...   \n",
       "3     2 46956 097.3684 116.6896 0014474 252.4864 107...   \n",
       "4     2 46956 097.3684 116.6896 0014474 252.4864 107...   \n",
       "...                                                 ...   \n",
       "8742  2 46687  53.0537 156.4222 0002423  24.7100 179...   \n",
       "8743  2 46698  53.0541 156.4452 0002064  21.4820 170...   \n",
       "8744  2 46694  53.0543 156.4335 0002340  36.3499 163...   \n",
       "8745  2 43171  35.0001 328.2871 0003494 312.5159  47...   \n",
       "8746  2 41456  98.1814   0.4081 0001288  80.5642 279...   \n",
       "\n",
       "                       tle_epoch  \n",
       "0     2020-12-07T10:27:24.244128  \n",
       "1     2020-12-07T10:27:24.244128  \n",
       "2     2020-12-07T10:27:24.244128  \n",
       "3     2020-12-07T10:27:24.244128  \n",
       "4     2020-12-07T10:27:24.244128  \n",
       "...                          ...  \n",
       "8742  2020-12-21T06:00:00.999648  \n",
       "8743  2020-12-21T06:00:00.999648  \n",
       "8744  2020-12-21T06:00:00.999648  \n",
       "8745  2020-12-21T06:07:08.546592  \n",
       "8746  2020-12-21T06:20:28.562208  \n",
       "\n",
       "[8747 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Open the file created above which contains our new TLE data from SpaceTrack\n",
    "new_tle_df = pd.read_csv(tmp_tle_file, names = ['norad','last_epoch', 'tle_line1', 'tle_line2', 'tle_epoch'])\n",
    "new_tle_df['last_epoch'] = pd.to_datetime(new_tle_df['last_epoch'], format='%Y%m%d%H%M%S%f')\n",
    "new_tle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3571it [00:48, 88.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=26931 for date 2020-12-19 18:51:21.912000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=26931 for date 2020-12-19 18:51:36.576000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=26931 for date 2020-12-19 18:52:10.464000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=42955 for date 2020-12-19 19:32:15.099000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=42955 for date 2020-12-19 19:32:35.233000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3636it [00:48, 82.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=41923 for date 2020-12-19 20:38:03.564000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=10514 for date 2020-12-19 20:39:29.268000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=10514 for date 2020-12-19 20:40:40.071000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3672it [00:49, 80.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=19851 for date 2020-12-19 21:21:35.146000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3739it [00:50, 76.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=12504 for date 2020-12-19 22:05:43.216000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3773it [00:50, 79.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=44885 for date 2020-12-19 23:41:34.771000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3804it [00:51, 65.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=13259 for date 2020-12-20 02:33:28.987000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3860it [00:52, 74.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=43690 for date 2020-12-20 03:53:15.863000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3926it [00:52, 68.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=38709 for date 2020-12-20 09:14:31.789000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=40028 for date 2020-12-20 09:43:59.065000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3950it [00:53, 65.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=29522 for date 2020-12-20 10:36:45.680000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3973it [00:53, 66.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find norad=39087 for date 2020-12-20 13:44:35.727000 - perhaps we have an updated socrates file?\n",
      "Cant find norad=39087 for date 2020-12-20 13:44:55.764000 - perhaps we have an updated socrates file?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8747it [01:41, 86.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding 13183 records to tle_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For each TLE record, find the corresponding socrates data and update their TLE\n",
    "count = 0\n",
    "all_success = True\n",
    "for index, row in tqdm(new_tle_df.iterrows()):\n",
    "    found = False\n",
    "    target = tle_df[(tle_df['sat1_norad'] == row['norad']) & (abs(tle_df['sat1_last_epoch']-row['last_epoch']) < pd.Timedelta('5 min'))].index\n",
    "    if len(target) > 0:\n",
    "        found = True\n",
    "        tle_df.at[target,'sat1_tle'] = row['tle_line1'] + ',' + row['tle_line2']\n",
    "        tle_df.at[target,'sat1_tle_epoch'] = row['tle_epoch']\n",
    "        count += 1\n",
    "    target = tle_df[(tle_df['sat2_norad'] == row['norad']) & (abs(tle_df['sat2_last_epoch']-row['last_epoch']) < pd.Timedelta('5 min'))].index\n",
    "    if len(target) > 0:\n",
    "        found = True\n",
    "        tle_df.at[target,'sat2_tle'] = row['tle_line1'] + ',' + row['tle_line2']\n",
    "        tle_df.at[target,'sat2_tle_epoch'] = row['tle_epoch']\n",
    "        count += 1\n",
    "    if not found:\n",
    "        print(f'Cant find norad={row[\"norad\"]} for date {row[\"last_epoch\"]} - perhaps we have an updated socrates file?')\n",
    "        all_success = False\n",
    "        #break\n",
    "print(f'Finished adding {count} records to tle_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check messages and remove ./tle2.csv if everything was okay.\n"
     ]
    }
   ],
   "source": [
    "# Save the TLE data to a pickle file\n",
    "tle_df[['sat_pair','tca_time','sat1_norad','sat2_norad','sat1_tle','sat1_tle_epoch','sat2_tle','sat2_tle_epoch']].to_pickle(tle_file_path, 'gzip')\n",
    "if all_success:\n",
    "    remove(tmp_tle_file)\n",
    "else:\n",
    "    print(f'Please check messages and remove {tmp_tle_file} if everything was okay.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soc_df, tle2_df = get_all_socrates_and_tle_data(socrates_files_path, tle_file_path)\n",
    "\n",
    "mtle_df12 = tle2_df[tle2_df['sat1_tle'].isnull()][['sat1_norad','sat1_last_epoch']].rename(columns={'sat1_norad':'norad','sat1_last_epoch':'last_epoch'})\n",
    "mtle_df22 = tle2_df[tle2_df['sat2_tle'].isnull()][['sat2_norad','sat2_last_epoch']].rename(columns={'sat2_norad':'norad','sat2_last_epoch':'last_epoch'})\n",
    "miss_tle_df2 = pd.concat([mtle_df12, mtle_df22])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
